import type { JSONValue } from './index';
export declare enum Token {
    TOK_EOF = "EOF",
    TOK_UNQUOTEDIDENTIFIER = "UnquotedIdentifier",
    TOK_QUOTEDIDENTIFIER = "QuotedIdentifier",
    TOK_RBRACKET = "Rbracket",
    TOK_RPAREN = "Rparen",
    TOK_COMMA = "Comma",
    TOK_COLON = "Colon",
    TOK_RBRACE = "Rbrace",
    TOK_NUMBER = "Number",
    TOK_CURRENT = "Current",
    TOK_ROOT = "Root",
    TOK_EXPREF = "Expref",
    TOK_PIPE = "Pipe",
    TOK_OR = "Or",
    TOK_AND = "And",
    TOK_EQ = "EQ",
    TOK_GT = "GT",
    TOK_LT = "LT",
    TOK_GTE = "GTE",
    TOK_LTE = "LTE",
    TOK_NE = "NE",
    TOK_FLATTEN = "Flatten",
    TOK_STAR = "Star",
    TOK_FILTER = "Filter",
    TOK_DOT = "Dot",
    TOK_NOT = "Not",
    TOK_LBRACE = "Lbrace",
    TOK_LBRACKET = "Lbracket",
    TOK_LPAREN = "Lparen",
    TOK_LITERAL = "Literal"
}
export declare type LexerTokenValue = JSONValue;
export interface LexerToken {
    type: Token;
    value: LexerTokenValue;
    start: number;
}
export interface ASTNode {
    type: string;
}
export interface ValueNode<T = LexerTokenValue> extends ASTNode {
    value: T;
}
export interface FieldNode extends ASTNode {
    name: LexerTokenValue;
}
export declare type KeyValuePairNode = FieldNode & ValueNode<ExpressionNodeTree>;
export interface ExpressionNode<T = ExpressionNodeTree> extends ASTNode {
    children: T[];
    jmespathType?: Token;
}
export interface ComparitorNode extends ExpressionNode {
    name: Token;
}
export declare type ExpressionNodeTree = ASTNode | ExpressionNode | FieldNode | ValueNode;
export declare const basicTokens: Record<string, Token>;
declare class StreamLexer {
    _current: number;
    tokenize(stream: string): LexerToken[];
    private consumeUnquotedIdentifier;
    private consumeQuotedIdentifier;
    private consumeRawStringLiteral;
    private consumeNumber;
    private consumeLBracket;
    private consumeOperator;
    private consumeLiteral;
    private looksLikeJSON;
}
export declare const Lexer: StreamLexer;
export default Lexer;
